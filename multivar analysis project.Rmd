---
title: "Final Project / ST 557"
author: "Dmitry Solovyev"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ICSNP)
library(MASS)
library(car)
library(rpart)
library(rpart.plot)
library(class)
library(corrplot)
library(rrcov)

```

# Goal 1)

## a)

```{r}
# Data formatting and Levene's Test for unequal variances
red <- read.csv('winequality-red.csv')
white <- read.csv('winequality-white.csv')
red$type <- 'red'
white$type <- 'white'
combined <- rbind(red, white)
combined$type <- as.factor(combined$type)

columns <- c('fixed.acidity', 'volatile.acidity', 'citric.acid', 
             'residual.sugar', 'chlorides', 'free.sulfur.dioxide', 
             'total.sulfur.dioxide', 'density', 'pH', 'sulphates', 
             'alcohol', 'quality')

p_values <- numeric(length(columns))
names(p_values) <- columns

for (attribute in columns) {
    result <- leveneTest(get(attribute) ~ type, data = combined)

    p_values[attribute] <- result$'Pr(>F)'[1]
}
print(p_values)

```
Before the start, we need to check if all the characteristics have equal variances. To do that, we conduct the Levene's test for unequal variances on each of the characteristics of the data. The p-values for the majority of variables are statistically significant, hence we cannot assume equal variances in our analysis.


```{r}
# T2 unequal variances 
n1 <- nrow(red[,1:12])
n2 <- nrow(white[,1:12])
p <- ncol(red[,1:12])
red.mean <- apply(red[,1:12], 2, mean)
white.mean <- apply(white[,1:12], 2, mean)
red.cov <- cov(red[,1:12])
white.cov <- cov(white[,1:12])
pooled.cov <- (red.cov*(n1-1) + white.cov*(n2-1))/(n1+n2-2)

T2stat.un <- (red.mean - white.mean) %*%
solve(red.cov/n1 + white.cov/n2) %*% (red.mean - white.mean)
T2stat.un

pval.un <- 1 - pchisq(T2stat.un, p)
pval.un
```
Based on the results of the Levene's test, to see if there is a difference in mean vectors between red and white wines, we conduct two-sample Hotelling T2 test by hand, since a corresponding in-built function cannot account for unequal variances. The final p-value is approximately 0 with t-statistic of 29432.68, so we have reject the null hypothesis that the mean vectors are the same for 11 chemical attributes.

```{r}
# MANOVA
Wilks.test(combined[,1:12], grouping=combined$type)

wine.manova <- manova(as.matrix(combined[,1:12]) ~ combined$type)
wine.manova

summary(wine.manova, test='Wilks')
```

To see which attributes seem to differ most, we  conduct Wilk's MANOVA to evaluate sample estimates individually. Based on the resulting output, we conclude that free.sulfur.dioxide, total.sulfur.dioxide and residual.sugar differ the most between red and white wines.


## b)

```{r}
wine.lda <- lda(type ~ fixed.acidity + volatile.acidity + citric.acid + 
                  residual.sugar + chlorides + free.sulfur.dioxide +   
                  total.sulfur.dioxide + density + pH + sulphates + 
                  alcohol + quality, data=combined)

red.xbar <- apply(red[,1:12], 2, mean)
white.xbar <- apply(white[,1:12], 2, mean)

wine.lda$scal

wine.ldaPred <- predict(wine.lda)

confMat.lda <- table(wine.ldaPred$class, combined$type)
confMat.lda

aper.lda <- 1 - sum(diag(confMat.lda))/sum(confMat.lda)
aper.lda

cat('The probability of classifying a new red wine correctly: ', 1580/1599)
```

For the classification rule, we decided to use the LDA method. LDA is particularly effective when the classes are linearly separable. It aims to project the data points onto a lower-dimensional space with good class separability, enhancing the performance of classification algorithms. In this problem, we trying to identify the type of wine (red or white), which seems like an appropriate situation to use LDA. The The model performed well, resulting in the apparent error rate (APER) of 0.005 and the accuracy of predicting a new red wine, if it was drawn fro the same population of red wines of 0.988.




```{r}
ntrain <- 0.8 * 6497
set.seed(42)
train.rows <- sample(1:6497, ntrain, replace=F)
train.rows <- sort(train.rows)

wine.train <- combined[train.rows,]
wine.test <- combined[-train.rows,]
wine.labels <- combined$type[train.rows] 

accuracy <- numeric(19)


for (k in 2:20) {
    knn_result <- knn(wine.train[, 1:12], wine.test[, 1:12], cl = wine.labels,
                      k = k)
    
    correct_predictions <- sum(wine.test$type == knn_result)
    accuracy[k - 1] <- correct_predictions / length(knn_result)
}

plot(2:20, accuracy, type = "b", col = "blue",
     xlab = "Number of Neighbors (k)", ylab = "Accuracy",
     main = "k-NN Accuracy for Different k Values")
for (k in 2:20) {
    text(k, accuracy[k - 1], labels = round(accuracy[k - 1], 3), pos = 1,
         cex = 0.6)
}

```
For comparison, we also implemented KNN classification method, which demonstrated slightly worse results in terms of total accuracy compared to the LDA. 

## c)

To cluster the wines into two clusters, we would use 2 methods: k-means and Model-based Clustering. K-means is computationally fast and allows for softer assumptions, where as model-based clustering can adapt to clusters of different sizes, shapes, and densities. This makes it suitable for complex datasets where these assumptions may not hold - which is particluarly useful given the unequal varainces and different sample sizes of the data. 

```{r}
set.seed(42)
clusters <- kmeans(combined[, 1:12], centers = 2)

combined$cluster <- as.factor(clusters$cluster)

table(combined$type, combined$cluster)

purity <- function(cluster, labels) {
  sum(apply(table(cluster, labels), 2, max)) / length(labels)
}

cluster_purity <- purity(combined$cluster, combined$type)
print(cluster_purity)
```
The k-means algorithm showed 78.5% accuracy.

```{r}
library(mclust)
library(cluster)
wine.mc <- Mclust(combined[,-1], G=2)

conf_matrix <- table(combined$type, wine.mc$classification)
conf_matrix

correct_predictions <- sum(apply(conf_matrix, 2, max))

total_predictions <- nrow(combined)
accuracy <- correct_predictions / total_predictions

print(accuracy)
```
Whereas the Model-based clustering showed 85% accuracy, which is significant improvement. This method proved to be more efficient, since we need to incorporate greater uncertainty due to the complexity of the data. 

# Goal 2)

## a)

```{r}
red2 <- red[,1:11]
red2$quality <- as.factor(red$quality)
Wilks.test(red2[,1:11], grouping=red2$quality)

red.manova <- manova(as.matrix(red2[,1:11]) ~ red2$quality)

summary(red.manova, test='Wilks')
```

The Wilk's MANOVA test showed statistically significant results, based on which we reject the null hypothesis that the mean vectors between red wines of different qualities are the same.

```{r}
red3 <- red2

red3$quality <- ifelse(red3$quality == 3 | red3$quality == 4, 'low',
                     ifelse(red3$quality == 5 | red3$quality == 6, 'medium',
                            ifelse(red3$quality == 7 | red3$quality == 8, 'high'
                                   , red3$quality)))


Wilks.test(red3[,1:11], grouping=red3$quality)

red3.manova <- manova(as.matrix(red3[,1:11]) ~ red3$quality)

summary(red3.manova, test='Wilks')

```
Similarly, if we divide wines into three quality categories, we also reject the null hypothesis that the mean vectors between red wines of different qualities are the same.


## b)

Here, we try two prediction methods: CART and KNN. Since we have 6 classes to predict, a big margin of error should be expected


```{r}
set.seed(42)
redntrain <- 0.8 * 1599

red.train.rows <- sample(1:1599, redntrain, replace=F)
red.train.rows <- sort(red.train.rows)

red.train <- red2[red.train.rows,]
red.test <- red2[-red.train.rows,]
red.labels <- red2$quality[red.train.rows]


red.tree <- rpart(quality ~ fixed.acidity + volatile.acidity + citric.acid + 
                    residual.sugar + chlorides + free.sulfur.dioxide +   
                    total.sulfur.dioxide + density + pH + sulphates +
                    alcohol, control=rpart.control(minsplit=5, minbucket=5), 
                  data=red2)

red.tree


prp(red.tree, type=1, digits=4, extra=1, varlen=0)

red.tree.testPred <- predict(red.tree, red.test)
head(red.tree.testPred)

red.tree.testPredCl <- predict(red.tree, red.test, type="class")

table(red.test$quality, red.tree.testPredCl)

mean(red.test$quality == red.tree.testPredCl)
```
The accuracy of prediction for CART with minsplit parameter of 5 is 0.65.

```{r}
set.seed(42)

redntrain <- 0.8 * 1599

red.train.rows <- sample(1:1599, redntrain, replace=F)
red.train.rows <- sort(red.train.rows)

red.train <- red2[red.train.rows,]
red.test <- red2[-red.train.rows,]
red.labels <- red2$quality[red.train.rows]


accuracy <- numeric(19)

accuracy <- numeric(19)

# Loop through k values from 2 to 20
for (k in 2:20) {
  # Apply k-NN
  knn_result <- knn(train = red.train[, -which(names(red2) == "quality")], 
                    test = red.test[, -which(names(red2) == "quality")], 
                    cl = red.labels, k = k)
  
  # Calculate and store accuracy
  accuracy[k - 1] <- mean(red.test$quality == knn_result)
}

# Plotting accuracy for each k
plot(2:20, accuracy, type = "b", col = "blue",
     xlab = "Number of Neighbors (k)", ylab = "Accuracy",
     main = "k-NN Accuracy for Different k Values")

```

Using the KNN algorithm with k-values 2 to 20 resulted in the highest value of accuracy of 0.53 when k = 13, which is still worse than CART. CART can capture non-linear relationships by splitting the data across different nodes. k-NN might struggle if the decision boundary is highly non-linear unless a suitable distance metric and scaling are applied.

## c)

```{r}
wine.pca <- princomp(red2[,1:11], cor = TRUE)

biplot(wine.pca)
screeplot(wine.pca)
plot(wine.pca$scores[,1:2], col=rainbow(10)[as.factor(combined$quality)])

wine.pca$loadings
```

The variables  have different units of measurement (e.g., grams, liters, pH levels). Without standardization, PCA might yield results that are biased towards variables with larger scales and units.. Alsom standardizing the data makes the PCA results more interpretable. It helps in understanding the relative importance of each variable in explaining the variation in the dataset.


```{r}
set.seed(42)
library(nnet)

train_indices <- sample(1:nrow(red2), 0.8 * nrow(red2))
train_set <- red2[train_indices, ]
test_set <- red2[-train_indices, ]


train_pca_all <- wine.pca$scores[train_indices, ]
test_pca_all <- wine.pca$scores[-train_indices, ]

model_pca_all <- multinom(quality ~ ., data = data.frame(quality = 
                                                           train_set$quality, 
                                                         train_pca_all))

predictions_pca_all <- predict(model_pca_all, newdata = data.frame(test_pca_all), 
                               type="class")

train_pca_2 <- wine.pca$scores[train_indices, 1:2]
test_pca_2 <- wine.pca$scores[-train_indices, 1:2]
model_pca_2 <- multinom(quality ~ ., data = data.frame(quality =
                                                         train_set$quality, 
                                                       train_pca_2))

predictions_pca_2 <- predict(model_pca_2, newdata = data.frame(test_pca_2),
                             type="class")

accuracy_pca_all <- mean(test_set$quality == predictions_pca_all)
accuracy_pca_2 <- mean(test_set$quality == predictions_pca_2)

list(accuracy_pca_all = accuracy_pca_all, accuracy_pca_2 = accuracy_pca_2)


```
The full PCA  captures more variance and information in the dataset since it includes all principal components resuling in the higher accuracy compared to the PCA with the first two components. The wine dataset might have complex relationships and patterns that are better captured when more dimensions are considered, which the full PCA version can encapsulate more effectively.

